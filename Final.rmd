---
# Section 1: Cluster Analysis
```{r}
setwd('/Users/emilyziyixiao/DataspellProjects/Framework&Method2/')

data1 = read.csv('froyo-1.csv')
data1
```


Question 3,4
```{r}
#str(data1)
rowSums(is.na(data1))
```

Question 5,6
```{r}
dataPrep = data1[2:7]
dataPrep$quality = data1$quality/mean(data1$quality)
dataPrep$variety = data1$variety/mean(data1$variety)
dataPrep$price = data1$price/mean(data1$price)
dataPrep$distance = data1$distance/mean(data1$distance)
dataPrep$courteousness = data1$courteousness/mean(data1$courteousness)
dataPrep$atmosphere = data1$atmosphere/mean(data1$atmosphere)
dataPrep
```
Question 7,8
```{r}
distances = dist(dataPrep,method = 'euclidean')
clusters = hclust(d = distances,method = 'ward.D2')
library(dendextend)
plot(color_branches(as.dendrogram(clusters),k = 2,groupLabels = F))
```
Question 9,10
```{r}
summary(dataPrep)
linear = lm(quality~.,dataPrep)
summary(linear)
```
Question 11,12
```{r}
library(rpart)
library(rpart.plot)
tree = rpart(quality~.,dataPrep,minbucket=10)
predTree = predict(tree,newdata=dataPrep)
sseTree = sum((predTree - dataPrep$quality)^2); sseTree
```
# Section 2: Text Mining

```{r}
library(dplyr); library(magrittr)
library(ggplot2); library(ggthemes)
library(stringr)
```

```{r}
install.packages('tidytext')
library(tidytext)
install.packages('lexicon')
library(lexicon)
install.packages('tidyr')
library(tidyr)
install.packages("wordcloud")
library(wordcloud)
install.packages("tm")
library(tm)
install.packages("rpart")
library(rpart); library(rpart.plot)
```

Question 19/20
What is the average length of reviews in terms of number of characters?
```{r}
setwd('/Users/liandi/Desktop/5205_Final Exam_Data')
beauty = read.csv('beauty.csv')

summary(nchar(beauty$review))
mean(nchar(beauty$review))

```

Question 21/22
What is the median number of words in reviews?
```{r}
summary(str_count(string = beauty$review,pattern = '\\S+'))
median(str_count(string = beauty$review,pattern = '\\S+'))
```

Question 23/24
Which of the following words are among the top 10 words mentioned in the reviews? Select one or more answers that are correct.
```{r}
library(dplyr); library(tidytext); library(magrittr)
beauty%>%
  unnest_tokens(input = review, output = word)%>%
  select(word)%>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(10)
```

Question 25/26
Use the ‘bing’ dictionary to classify words in reviews into positive and negative. The bing dictionary of words can be accessed using tidytext::get_sentiments(‘bing’). What is the average number of positive words in a review?

```{r}
as.data.frame(get_sentiments('bing'))[1:50,]
beauty%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = review)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()
```

Question 27/28
Use the ‘bing’ dictionary to classify words in reviews into positive and negative. The bing dictionary of words can be accessed using tidytext::get_sentiments(‘bing’). What is the average number of negative words in a review?
```{r}
as.data.frame(get_sentiments('bing'))[1:50,]
beauty%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = review)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()
```

Question 29/30
Examine the emotions expressed in the reviews using the “nrc” dictionary. The nrc dictionary can be accessed using tidytext::get_sentiments(‘nrc’) OR by reading nrc.csvDownload nrc.csv  into an R object.

How many words reflect “joy”?

```{r}
nrc = read.csv('nrc.csv')

beauty%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = review)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  arrange(desc(n))

```

Question 31/32
Use the afinn dictionary to determine the sentiment score of each review. The afinn dictionary can be accessed using tidytext::get_sentiments(‘afinn’) OR by reading afinn.csvDownload afinn.csv into an R object.

Compute the sentiment score for each review. Next, average the sentiment of all reviews. What is the average sentiment score for a review?

```{r}
afinn = read.csv('afinn.csv')

beauty %>%
  select(id,review)%>%
  group_by(id)%>%
  unnest_tokens(output=word,input=review)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  summarize(min=min(reviewSentiment),
            max=max(reviewSentiment),
            median=median(reviewSentiment),
            mean=mean(reviewSentiment))
```

# Section 3 Recommender Systems

```{r}
library(recommenderlab)
data(MovieLense)
```

Question 34
Briefly outline the process underlying collaborative filtering. Limit your answer to three lines.
```{r}
# 1. The user express his/her preference by rating system; 2. The system matches the user's ratings with other users to find people with similar tastes；3. Recommend item that rated highly but not yet being rated by this users
```

Question 35,36
How many movies did user “115” rate?

```{r}
nratings(MovieLense['115',])
```

Question 37,38
What was the mean rating of movies by user “115”?

```{r}
mean(getRatings(MovieLense['115']))
```

Question 39,40
Using a seed of 1706, split the dataset, retaining 80% in the train sample using the sample() function. Call the object containing the train data, train and the object containing the test data, test.How many rows are in the train dataset?
```{r}
set.seed(1706)
split = sample(x = nrow(MovieLense), size = 0.8 * nrow(MovieLense))
train = MovieLense[split,]
test = MovieLense[-split,]
nrow(train)
```

Question 41,42
Construct a user-based collaborative filtering recommender using the train data. Set the parameter nn to 10, method to ‘cosine’, and normalize to ‘center’ in the recommender function. Call this recommender, recom_ubcf. Use recom_ubcf to predict the top three recommended movies for each user in the test data. What are the top three recommended movies for user “115”?

```{r}
recom_ubcf = Recommender(
  train,
  method = 'UBCF',
  parameter = list(
    method = 'cosine',
    nn = 10,
    normalize = 'center'
  )
)
pred_ubcf_top3 = predict(recom_ubcf,
                         newdata = test,
                         method = 'topNList',
                         n = 3)

getList(pred_ubcf_top3)['115']


```

Question 43,44
Based on the user-based collaborative filtering recommender, recom_ubcf that was constructed in the previous question, what is the predicted rating for the top recommended movie for user “115”?

```{r}
as(pred_ubcf_top3,'matrix')['115',"G.I. Jane (1997)"]
```

Question 45,46
One of the oldest approaches to recommendations involves recommending the most popular item. Although less widely used today, we still see this in the form of Top 50 Music Hits, Billboard Top Hits, and New York Times Bestsellers. The underlying assumption is that if most people like a movie, a book or a song, you will like it too.

Create non-personalized recommendations with the POPULAR method using the train data. Set the parameter normalize to ‘center’ (although, center is the default). Call this recommender, recom_popular. Use recom_popular to predict the top 3 recommended movies for each user in the test data. Based on the results, what are the top 3 recommended movies for user ‘115’?

```{r}
recom_popular = Recommender(train,
                            method = 'POPULAR',
                            parameter = list(normalize = 'center'))
pred_popular_top3 = predict(recom_popular,
                            newdata = test,
                            type = 'topNList',
                            n = 3)
getList(pred_popular_top3)['115']
```




# Section 4 Time Series Analysis

```{r}
library(ggplot2);library(ggthemes);library(gridExtra)  # For plots
library(quantmod);library(xts);library(zoo) # For using xts class objects
library(forecast) # Set of forecasting functions
library(fpp); library(fpp2) # Datasets from Forecasting text by Rob Hyndman
library(tseries) # for a statistical test
library(dplyr) # Data wrangling

```

Question 48,49
For the remaining questions in this section that involve analysis, use a dataset containing monthly closing prices for Amazon Stock. Read the data in amazon.rds using readRDS as follows: readRDS(file=‘amazon.RDS’).

The goal is to forecast Amazon stock starting in 2018 using all historical data up until the end of 2017 in the Amazon stock data. To do this set, split amazon data into train and test such that train data ends on Dec, 2017 and test data begins on Jan, 2018. Call the train data, train and test data, test.

How many months are in the test dataset?

```{r}
amazon = readRDS(file='amazon.RDS')
train = window(amazon,end=c(2017,12))
test = window(amazon,start=c(2018,01))
test
length(test)/3

```

Question 50,51
Use a Naive Forecast to make predictions over the test data. What is the point forecast for Dec, 2021?

```{r}
naive_model = naive(train,h=48)
naive_model$mean
window(naive_model$mean,c(2021,12))

```

Question 52,53
Examine the accuracy of the above prediction from Naive Forecast on the train sample. What is the Root Mean Squared Error (RMSE) of the predictions in the train sample?

```{r}
accuracy(naive_model)
```

Question 54,55
What is the RMSE of the Naive Forecast in the test data?

```{r}
accuracy(naive_model, x = amazon)
```

Question 56,57

Now, let’s use an ARIMA model. Since, there are a large number of parameters with which to define the ARIMA model, let’s use the auto.arima() function to automatically determine the best parameters. Set it up to do an exhaustive search by setting stepwise to F and approximation to F. Call this auto_arima_model. How many ordinary moving average lag variables have been used in auto_arima_model?


```{r}
auto_arima_model = auto.arima(y = train,d = 1,D = 1,stepwise = F,approximation = F)
auto_arima_model
```

Question 58,59

How many seasonal autoregressive lag variables have been used in auto_arima_model created in the previous question?

```{r}
# Code see above
```

Question 60,61
Use the auto_arima_model to make predictions over the test data. What is the point forecast for Dec, 2021?
```{r}
auto_arima__forecast = forecast(auto_arima_model,h=48)
window(auto_arima__forecast$mean,c(2021,12))
```

Question 62/63
What is the RMSE of auto_arima_model in the test dataset?


```{r}
accuracy(auto_arima__forecast, x = apple)
```

Question 64,65

What is the RMSE of auto_arima_model in the train dataset?

```{r}
code above
```




